{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing\n",
    "\n",
    "Natural Language Processing (or NLP) is a discipline in computing that deals with the communication between natural(human) languages and computer language. A common example of NLP is something like spellcheck or autocomplete.\n",
    "\n",
    "## Recurrent Neural Networks\n",
    "\n",
    "In this tutorial we will introduce a new kind of neural network that is much capable of processing sequential data such as text or characters called a recurrent neural network (RNN)\n",
    "\n",
    "we will learn how to use reccurent neural network to do the following:\n",
    "\n",
    "* Sentiment Analysis\n",
    "* Character Generation\n",
    "\n",
    "RNN's are fairly complex and come in many different forms so in this tutorial we will focus on how they work and the kind of problems they are best suited for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
      "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
     ]
    }
   ],
   "source": [
    "vocab = {}  # maps word to integer representing it\n",
    "word_encoding = 1\n",
    "def bag_of_words(text):\n",
    "  global word_encoding\n",
    "\n",
    "  words = text.lower().split(\" \")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example\n",
    "  bag = {}  # stores all of the encodings and their frequency\n",
    "\n",
    "  for word in words:\n",
    "    if word in vocab:\n",
    "      encoding = vocab[word]  # get encoding from vocab\n",
    "    else:\n",
    "      vocab[word] = word_encoding\n",
    "      encoding = word_encoding\n",
    "      word_encoding += 1\n",
    "    \n",
    "    if encoding in bag:\n",
    "      bag[encoding] += 1\n",
    "    else:\n",
    "      bag[encoding] = 1\n",
    "  \n",
    "  return bag\n",
    "\n",
    "text = \"this is a test to see if this test will work is is test a a\"\n",
    "bag = bag_of_words(text)\n",
    "print(bag)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't really the way we would do this in practice, but I hope it gives you an idea of how bag of words works. Notice that we've lost the order in which words appear. In fact, let's look at how this encoding works for the two sentences we showed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Dataset\n",
    "\n",
    "Well start by loading in the IMDB movie review dataset from keras. This dataset contains 25,000 reviews from IMDB where each one is already preprocessed and has label as either positive or negative. Each review is encoded by integers that represents how common a word is in the entire dataset. For example a word encoded by the integer 3 mean that it is the 3rd most common word in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_label) = imdb.load_data(num_words = VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     1,   194,\n",
       "        1153,   194,  8255,    78,   228,     5,     6,  1463,  4369,\n",
       "        5012,   134,    26,     4,   715,     8,   118,  1634,    14,\n",
       "         394,    20,    13,   119,   954,   189,   102,     5,   207,\n",
       "         110,  3103,    21,    14,    69,   188,     8,    30,    23,\n",
       "           7,     4,   249,   126,    93,     4,   114,     9,  2300,\n",
       "        1523,     5,   647,     4,   116,     9,    35,  8163,     4,\n",
       "         229,     9,   340,  1322,     4,   118,     9,     4,   130,\n",
       "        4901,    19,     4,  1002,     5,    89,    29,   952,    46,\n",
       "          37,     4,   455,     9,    45,    43,    38,  1543,  1905,\n",
       "         398,     4,  1649,    26,  6853,     5,   163,    11,  3215,\n",
       "       10156,     4,  1153,     9,   194,   775,     7,  8255, 11596,\n",
       "         349,  2637,   148,   605, 15358,  8003,    15,   123,   125,\n",
       "          68, 23141,  6853,    15,   349,   165,  4362,    98,     5,\n",
       "           4,   228,     9,    43, 36893,  1157,    15,   299,   120,\n",
       "           5,   120,   174,    11,   220,   175,   136,    50,     9,\n",
       "        4373,   228,  8255,     5, 25249,   656,   245,  2350,     5,\n",
       "           4,  9837,   131,   152,   491,    18, 46151,    32,  7464,\n",
       "        1212,    14,     9,     6,   371,    78,    22,   625,    64,\n",
       "        1382,     9,     8,   168,   145,    23,     4,  1690,    15,\n",
       "          16,     4,  1355,     5,    28,     6,    52,   154,   462,\n",
       "          33,    89,    78,   285,    16,   145,    95], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
    "test_data = sequence.pad_sequences(test_data, MAXLEN)\n",
    "train_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2843041 (10.85 MB)\n",
      "Trainable params: 2843041 (10.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 17s 25ms/step - loss: 0.4350 - acc: 0.8005 - val_loss: 0.3257 - val_acc: 0.8698\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.2419 - acc: 0.9083 - val_loss: 0.3042 - val_acc: 0.8694\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.1835 - acc: 0.9345 - val_loss: 0.3954 - val_acc: 0.8430\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.1545 - acc: 0.9446 - val_loss: 0.2894 - val_acc: 0.8906\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.1313 - acc: 0.9548 - val_loss: 0.2876 - val_acc: 0.8894\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.1103 - acc: 0.9621 - val_loss: 0.3113 - val_acc: 0.8860\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.0983 - acc: 0.9669 - val_loss: 0.3436 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.0856 - acc: 0.9711 - val_loss: 0.4258 - val_acc: 0.8788\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.0767 - acc: 0.9750 - val_loss: 0.4410 - val_acc: 0.8692\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.0684 - acc: 0.9776 - val_loss: 0.3959 - val_acc: 0.8870\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['acc'])\n",
    "\n",
    "histpry = model.fit(train_data, train_labels, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And well evaluate the model on out training data to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4805 - acc: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4805392920970917, 0.8593999743461609]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(test_data, test_label)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
    "\n",
    "text = \"that movie was just amazing, so amazing\"\n",
    "encode = encode_text(text)\n",
    "print(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was just amazing so amazing\n"
     ]
    }
   ],
   "source": [
    "# while were at it lets make a decode function\n",
    "\n",
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num != PAD:\n",
    "            text += reverse_word_index[num] + \" \"\n",
    "\n",
    "    return text[:-1]\n",
    "\n",
    "print(decode_integers(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 199ms/step\n",
      "[0.8773501]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[0.31494194]\n"
     ]
    }
   ],
   "source": [
    "# now time to make a prediction\n",
    "\n",
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred) \n",
    "    print(result[0])\n",
    "\n",
    "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
    "predict(negative_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Play Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding = 'utf-8')\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "Since this text isn't encoded yet well need to do that ourself. We are going to encode each unique character as a different integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "    return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First Citizen\n",
      "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "print(\"Text:\", text[:13])\n",
    "print(\"Encoded:\", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "    try:\n",
    "        ints = ints.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return ''.join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_intput_target(chunk) :\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequence.map(split_intput_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "OUTPUT\n",
      "irst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you \n",
      "\n",
      "OUTPUT\n",
      "re all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you k\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(2):\n",
    "    print(\"\\n\\nEXAMPLE\\n\")\n",
    "    print(\"INPUT\")\n",
    "    print(int_to_text(x))\n",
    "    print(\"\\nOUTPUT\")\n",
    "    print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5330241 (20.33 MB)\n",
      "Trainable params: 5330241 (20.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape = [batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences = True,\n",
    "                             stateful = True,\n",
    "                             recurrent_initializer = 'glorot_uniform'),\n",
    "                             tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS,BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) --> (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"--> (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[-9.17716883e-04  2.05973512e-03 -1.29466504e-02 ...  7.24846916e-03\n",
      "    1.18075637e-04  8.22192989e-03]\n",
      "  [ 4.43683332e-03 -1.94420828e-03 -1.09162945e-02 ...  9.60852113e-03\n",
      "   -3.02824820e-03  9.73279122e-03]\n",
      "  [ 4.28345427e-03  1.85428909e-03 -1.50364274e-02 ...  9.72239207e-03\n",
      "   -1.18152273e-03  3.63048282e-03]\n",
      "  ...\n",
      "  [ 8.22923426e-03  4.73024836e-03 -1.93125277e-03 ...  1.02472249e-02\n",
      "   -2.51482613e-03 -9.06765461e-03]\n",
      "  [ 1.14468699e-02  1.34245143e-03 -2.17978796e-03 ...  1.20051727e-02\n",
      "   -4.81724739e-03 -3.78987845e-03]\n",
      "  [ 1.49077782e-02  7.57269852e-04 -8.42376985e-03 ...  1.40316170e-02\n",
      "   -7.97890592e-03 -5.31198271e-03]]\n",
      "\n",
      " [[ 9.64803435e-03  7.92764314e-03 -4.81153792e-03 ...  2.21281569e-03\n",
      "    8.79527011e-04 -1.13362800e-02]\n",
      "  [ 4.95439442e-03  5.53762168e-03  2.03680852e-03 ...  7.15896999e-03\n",
      "    3.23626585e-03 -1.42284790e-02]\n",
      "  [ 6.30202796e-03  4.41909628e-03  9.34002222e-04 ...  9.25146695e-03\n",
      "    4.11982927e-03 -7.07802968e-03]\n",
      "  ...\n",
      "  [ 2.24570557e-03 -9.93888476e-04 -2.50181183e-03 ...  1.05943233e-02\n",
      "   -3.11118551e-03 -9.84204467e-03]\n",
      "  [ 7.21198414e-03 -4.47819708e-03 -4.83590737e-03 ...  1.29340682e-02\n",
      "    1.07882707e-03 -5.06424066e-03]\n",
      "  [ 2.33009551e-03 -8.04327056e-03  7.91120809e-04 ...  9.14265029e-03\n",
      "   -1.03536318e-03 -5.11362310e-03]]\n",
      "\n",
      " [[ 1.78956881e-03 -2.46185018e-03  3.73392296e-03 ...  1.42102148e-02\n",
      "   -2.78934231e-03  4.39639343e-03]\n",
      "  [-5.71188866e-04  4.16818075e-03  3.67514859e-03 ...  1.02510974e-02\n",
      "   -6.24856353e-03  2.08813348e-03]\n",
      "  [ 9.94877075e-04  4.26407252e-03  3.21714766e-03 ...  1.07932072e-02\n",
      "   -3.08773946e-03  8.26493185e-03]\n",
      "  ...\n",
      "  [ 5.76825300e-03 -6.33879798e-03  8.18315311e-06 ...  9.70279519e-03\n",
      "   -9.61638056e-03 -5.89822326e-03]\n",
      "  [ 1.63835450e-03 -8.37858766e-03  3.03625083e-03 ...  7.84346368e-03\n",
      "   -4.20609815e-03 -8.18545651e-03]\n",
      "  [-2.03923206e-03 -5.98936528e-03  8.70075915e-03 ...  1.04068471e-02\n",
      "   -7.57607690e-04 -1.22554498e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-9.01648402e-03  7.85569719e-04 -6.49871118e-03 ... -7.98803568e-03\n",
      "    1.45065540e-03 -4.17780317e-03]\n",
      "  [-1.49497669e-02  2.15015328e-03 -3.62482970e-04 ... -4.38360311e-03\n",
      "   -1.65737793e-03 -3.60954460e-03]\n",
      "  [-7.89019279e-03 -1.61273964e-03  2.96945800e-04 ... -1.02341478e-03\n",
      "   -5.18824765e-03  5.97241684e-04]\n",
      "  ...\n",
      "  [ 8.45838618e-03  2.80771579e-04 -6.03326643e-03 ...  6.82808878e-03\n",
      "   -5.63858589e-03  1.50153658e-03]\n",
      "  [ 8.06830544e-03 -3.54587985e-03 -3.98231065e-03 ...  7.63073657e-03\n",
      "   -6.43898500e-04 -2.12253584e-03]\n",
      "  [ 9.80167463e-03 -2.96243210e-03 -5.76629443e-03 ...  1.00327423e-02\n",
      "   -2.76360381e-03 -4.87112673e-04]]\n",
      "\n",
      " [[ 6.97990507e-03 -2.14286149e-03  1.70340482e-03 ...  2.12449231e-03\n",
      "   -5.22354152e-03  8.45534727e-04]\n",
      "  [ 5.46595454e-03 -3.86720931e-04  5.03043178e-04 ...  1.16128586e-02\n",
      "   -8.08460731e-03  3.43039865e-03]\n",
      "  [ 6.44378085e-03  5.26015705e-04 -1.06599904e-03 ...  1.27599314e-02\n",
      "   -5.95117779e-03  7.86325987e-03]\n",
      "  ...\n",
      "  [ 9.15884227e-03  3.83945415e-03 -5.03810216e-03 ...  1.23643037e-02\n",
      "    1.66537624e-03 -4.40299371e-03]\n",
      "  [ 8.31677462e-04  5.16943401e-03  4.90734703e-04 ...  1.37037765e-02\n",
      "   -1.48717337e-03 -4.87353420e-03]\n",
      "  [ 2.44162371e-03  8.57968349e-03 -5.35544567e-03 ...  1.43739423e-02\n",
      "   -3.92313232e-04 -8.27985071e-03]]\n",
      "\n",
      " [[ 2.67794612e-03  8.54629558e-03 -8.30774195e-03 ...  1.36218010e-03\n",
      "   -2.68617668e-03 -9.54540633e-03]\n",
      "  [ 7.90400431e-03  3.68463807e-03 -8.34862795e-03 ...  5.60202030e-03\n",
      "    3.46142449e-03 -3.24441260e-03]\n",
      "  [ 3.29528516e-03 -8.95091100e-04 -1.08167820e-03 ...  3.62622435e-03\n",
      "    2.43184157e-03 -2.48342589e-03]\n",
      "  ...\n",
      "  [ 9.97975841e-03  5.90923987e-03 -5.55606652e-03 ...  6.46949792e-03\n",
      "   -3.76357045e-03  2.37968517e-04]\n",
      "  [ 6.05879398e-03  7.08859693e-03 -1.31344469e-03 ... -2.69741728e-03\n",
      "    6.00089086e-04 -1.67731661e-03]\n",
      "  [ 5.70502318e-03  7.20244180e-03 -1.41272205e-04 ...  9.04583931e-03\n",
      "   -2.94365967e-03  1.49115256e-03]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[-0.00091772  0.00205974 -0.01294665 ...  0.00724847  0.00011808\n",
      "   0.00822193]\n",
      " [ 0.00443683 -0.00194421 -0.01091629 ...  0.00960852 -0.00302825\n",
      "   0.00973279]\n",
      " [ 0.00428345  0.00185429 -0.01503643 ...  0.00972239 -0.00118152\n",
      "   0.00363048]\n",
      " ...\n",
      " [ 0.00822923  0.00473025 -0.00193125 ...  0.01024722 -0.00251483\n",
      "  -0.00906765]\n",
      " [ 0.01144687  0.00134245 -0.00217979 ...  0.01200517 -0.00481725\n",
      "  -0.00378988]\n",
      " [ 0.01490778  0.00075727 -0.00842377 ...  0.01403162 -0.00797891\n",
      "  -0.00531198]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tf.Tensor(\n",
      "[-0.00091772  0.00205974 -0.01294665 -0.01102437  0.00885246  0.00350611\n",
      "  0.00248048 -0.00198216 -0.00029814 -0.00306895 -0.0025068  -0.00679063\n",
      " -0.00581012 -0.00015235 -0.00383247  0.00264474 -0.00647019 -0.00157837\n",
      " -0.00361783 -0.00522902 -0.00991746  0.00111962  0.00993568  0.00844753\n",
      "  0.00169271 -0.0045408   0.00195838  0.00245238 -0.00359592  0.0071556\n",
      "  0.00710109 -0.00416773  0.00733918 -0.01170573 -0.00541775 -0.00611222\n",
      " -0.00576066  0.00645136  0.00341756  0.0075292  -0.00585935  0.01876229\n",
      "  0.01149772  0.00828716  0.00092977  0.00139835 -0.01508622  0.00383708\n",
      " -0.00044344  0.00767208  0.00052797  0.00396218  0.00406228  0.01087895\n",
      " -0.0040208  -0.00421738 -0.00291978 -0.01043626 -0.00176217 -0.00527899\n",
      "  0.00749619  0.00477153  0.00724847  0.00011808  0.00822193], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"eiqVhT$TIpY,jrvkETC-sPoVoolHfHyVlAWk;w-OVxJutrmuQoUUY3''k.Fi\\nGpjSsaCDEdEjdNUM?!.\\n.iZYOIVLJYEQlaZwjpg\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "172/172 [==============================] - 208s 1s/step - loss: 2.4808\n",
      "Epoch 2/2\n",
      "172/172 [==============================] - 268s 2s/step - loss: 1.8851\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs=2, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "# checkpoint_num = 2\n",
    "# model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/ckpt_\" + str(checkpoint_num)))\n",
    "# model.build(tf.TensorShape([1, None]))\n",
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 800\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "    \n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romeon with have brieg a\n",
      "Shase gite fart is\n",
      "Alled with thay to will'o the cors.\n",
      "That her canlive te to be to sinm in take apoct, the lead on you more; we thank you forturd stull maze andows.\n",
      "\n",
      "KIANENLA:\n",
      "Hervollmbow\n",
      "In Buttoling termt ag then, will repust shall by thus.\n",
      "\n",
      "GONTELSO:\n",
      "Hay is his were was that cuttread calf that dient'd you he? Mary corme thene;\n",
      "Matioms you.\n",
      "Thy ford wood, lost be doue bean, and this dedvit to have the ne\n",
      "&rows to her sens wo will baind to withan\n",
      "A diuth off goods.\n",
      "\n",
      "GROZIE:\n",
      "thou thy boand!\n",
      "Houths, that un reasunh; same, than the send as ad. Thy that?\n",
      "\n",
      "TRANEO:\n",
      "What, nor thar we with a knowl: no heach two you. Vecaisca, thy father-mact:\n",
      "My not speim fort y os Guchter, gons\n",
      "he hade anverarvest ere sheaw these selil: come\n",
      "Of te me; so we sto bekn nece-\n",
      "Om thin straws dome\n"
     ]
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
